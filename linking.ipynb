{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from preprocessing import clean_gt, clean_raw, label_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = pickle.load(open('data/train_test_eval_filenames_new.pkl', 'rb'))\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train = 94, test = 30, eval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# new_split = {\"train\":[], \"test\": [], \"eval\": []}\n",
    "# for key in split:\n",
    "#     for page in split[key]:\n",
    "#         mag = page.split(\"_\")[0].split(\"-\")[0]\n",
    "#         year = page.split(\"_\")[1]\n",
    "        \n",
    "#         if mag == \"dkm\" and (year == \"1941\" or year == \"2010\"):\n",
    "#             new_split[\"train\"].append(page)\n",
    "#         if (year == \"1990\"):\n",
    "#             new_split[\"test\"].append(page)\n",
    "#         if mag ==\"sbz\" and (year == \"1895\" or year == \"1940\" or year == \"1965\" or year == \"2010\"):\n",
    "#             new_split[\"train\"].append(page)\n",
    "\n",
    "# eval_set = random.sample(new_split[\"train\"], int(len(new_split[\"train\"])/10)) #set 10% of train aside for eval\n",
    "# for page in eval_set:\n",
    "#     new_split[\"train\"].remove(page)\n",
    "# new_split[\"eval\"] = eval_set\n",
    "\n",
    "# with open('train_test_eval_filenames_new.pkl', 'wb') as out:\n",
    "#     pickle.dump(new_split, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data = {\n",
    "    \"train\": [],\n",
    "    \"test\": [],\n",
    "    \"eval\": []\n",
    "}\n",
    "gt_data = []\n",
    "for mag in [\"dkm\", \"sbz\"]:\n",
    "    for year in os.listdir(f'data/raw/link/{mag}'):\n",
    "        with open(os.path.join(\"data/raw/link\", mag, year)) as f:\n",
    "            input_linked = json.load(f)\n",
    "        with open(os.path.join(\"data/ground-truth\", mag, year)) as f:\n",
    "            gt = json.load(f)\n",
    "        gt = clean_gt(gt)\n",
    "        gt_data += gt\n",
    "        input_linked = clean_raw(input_linked)\n",
    "\n",
    "        #due to non-determinism in the flair NER:\n",
    "        all_refs_gt = [g[\"page\"]+g[\"coord\"] for g in gt] \n",
    "        all_refs_linked = [ent[\"page\"]+ent[\"coord\"] for l in input_linked for ent in l]\n",
    "        all_valid_refs = set(all_refs_gt).intersection(set(all_refs_linked))\n",
    "\n",
    "        for ent_variations in input_linked:\n",
    "            for key in split:\n",
    "                ent_instances = []\n",
    "                for ent in ent_variations:\n",
    "                    if ent[\"page\"] in split[key]:\n",
    "                        if (ent[\"page\"]+ent[\"coord\"]) in all_valid_refs:\n",
    "                            ent_instances.append({\"ent\": ent, \"label\": label_entity(ent, gt)})\n",
    "                if ent_instances:\n",
    "                    data[key].append(ent_instances)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open(\"data/processed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.notebook import  tqdm\n",
    "from candidate_generation import create_metagrid_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_obsolete_abbrevs(fnames, abbr_firstname, prep_for_query=True):\n",
    "    \"\"\"\n",
    "    Remove abbreviated firstnames, that are already covered by full firstnames.\n",
    "    e.g. fnames = [\"R.\", \"Richard\"] => fnames = [\"Richard\"]\n",
    "    \"\"\"\n",
    "    cleaned_abbr_fnames = []\n",
    "    for abbr_group in abbr_firstname:  # this is now a list\n",
    "        cleaned_abbr_group = []\n",
    "        for abbr in abbr_group:\n",
    "            is_obsolete = False\n",
    "            abbr = abbr.rstrip(\".\")\n",
    "            for fname in fnames:\n",
    "                if fname.startswith(abbr):\n",
    "                    is_obsolete = True\n",
    "            if not is_obsolete:\n",
    "                if prep_for_query:\n",
    "                    cleaned_abbr_group.append(abbr + \"*\")\n",
    "                else:\n",
    "                    cleaned_abbr_group.append(abbr + \".\")\n",
    "        cleaned_abbr_fnames.append(cleaned_abbr_group)\n",
    "    \n",
    "    return cleaned_abbr_fnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SPARQLWrapper\n",
    "from SPARQLWrapper import JSON, SPARQLExceptions, SPARQLWrapper\n",
    "import pprint as pp\n",
    "def get_candidates_fuseki(person):\n",
    "    \"\"\"\n",
    "    Call the RDF library to find candidates.\n",
    "    Note to self: Consider limiting the query to top X answers if querying times are slow.\n",
    "    \"\"\"\n",
    "    #unfortunately, checks like the one below doesn't find people like \"Beethoven\"\n",
    "    if len(person[\"lastname\"]) == 0 or (len([c for x in \" \".join(person[\"lastname\"]) for c in x]) < 2) or (not person[\"firstname\"] and not person[\"abbr_firstname\"]):\n",
    "        return {}\n",
    "\n",
    "    fnames = person[\"firstname\"].split(\" \")\n",
    "    print(fnames)\n",
    "    #fnames = list(set([x for y in fnames for x in y]))\n",
    "    abbr_fnames = remove_obsolete_abbrevs(fnames, person[\"abbr_firstname\"])\n",
    "    abbr_fnames = list(set([x for y in abbr_fnames for x in y if x!=\"*\"]))\n",
    "    #abbr_fnames = \" \".join(abbr_fnames)\n",
    "    print(abbr_fnames)\n",
    "\n",
    "    lastname = person[\"lastname\"].split(\" \")\n",
    "    print(lastname)\n",
    "    if fnames == [\"\"]:\n",
    "        names = \" AND \".join(abbr_fnames + lastname)\n",
    "    else:\n",
    "        names = \" AND \".join(fnames + abbr_fnames + lastname)\n",
    "    print(names)\n",
    "    if(len(lastname) > 1):\n",
    "        lastname = \" \".join(lastname)\n",
    "    else:\n",
    "        lastname = lastname[0]\n",
    "    pref_names_format = lastname + \", \" + \" \".join(fnames) \n",
    "    query_string = \"\"\"\n",
    "        PREFIX gndo: <https://d-nb.info/standards/elementset/gnd#>\n",
    "        PREFIX text: <http://jena.apache.org/text#>\n",
    "        SELECT *\n",
    "        WHERE {{\n",
    "            {{?x text:query \"{0}\" . }}\n",
    "            UNION\n",
    "            {{?x text:query (gndo:variantNameForThePerson \"{0}\") . }}\n",
    "            UNION\n",
    "            {{?x gndo:preferredNameForThePerson ?s .\n",
    "            FILTER (?s = \"{1}\") . }}\n",
    "            ?x a gndo:DifferentiatedPerson .\n",
    "            ?x gndo:gndIdentifier ?gid .\n",
    "            ?x gndo:preferredNameEntityForThePerson ?name .\n",
    "            OPTIONAL {{ ?name gndo:prefferedNameForThePerson ?prefVarName . }}\n",
    "            OPTIONAL {{ ?name gndo:forename ?prefForename . }}\n",
    "            OPTIONAL {{ ?name gndo:prefix ?prefPrefix . }}\n",
    "            OPTIONAL {{ ?name gndo:surname ?prefSurname . }}\n",
    "            OPTIONAL {{ ?name gndo:personalName ?prefPersName . }}\n",
    "            OPTIONAL {{ ?name gndo:nameAddition ?prefNameAddition . }}\n",
    "            OPTIONAL {{ ?x gndo:variantNameEntityForThePerson ?y . \n",
    "                OPTIONAL {{ ?y gndo:variantNameForThePerson ?varName . }}\n",
    "                OPTIONAL {{ ?y gndo:forename ?varForename . }}\n",
    "                OPTIONAL {{ ?y gndo:prefix ?varPrefix . }}\n",
    "                OPTIONAL {{ ?y gndo:surname ?varSurname . }}\n",
    "                OPTIONAL {{ ?y gndo:personalName ?varPersName . }}\n",
    "                OPTIONAL {{ ?y gndo:nameAddition ?varNameAddition . }}\n",
    "            }}\n",
    "            OPTIONAL {{ ?x gndo:professionOrOccupationAsLiteral ?jobliteral . }}\n",
    "            OPTIONAL {{ ?x gndo:gndSubjectCategory ?category . }}\n",
    "            OPTIONAL {{ ?x gndo:academicDegree ?academic . }}\n",
    "            OPTIONAL {{ ?x gndo:professionOrOccupation ?job . }}\n",
    "            OPTIONAL {{ ?x gndo:dateOfBirth ?birthdate . }}\n",
    "            OPTIONAL {{ ?x gndo:dateOfDeath ?deathdate . }}\n",
    "            OPTIONAL {{ ?x gndo:placeOfBirth ?birthplace . }}\n",
    "            OPTIONAL {{ ?x gndo:placeOfDeath ?deathplace . }}\n",
    "            OPTIONAL {{ ?x gndo:placeOfBirthAsLiteral ?birthplaceLiteral . }}\n",
    "            OPTIONAL {{ ?x gndo:placeOfDeathAsLiteral ?deathplaceLiteral . }}\n",
    "            OPTIONAL {{ ?x gndo:placeOfActivity ?activeplace . }}\n",
    "            OPTIONAL {{ ?x gndo:periodOfActivity ?activeperiod . }}\n",
    "            OPTIONAL {{ ?x gndo:biographicalOrHistoricalInformation ?desc . }}\n",
    "            OPTIONAL {{ ?x gndo:geographicAreaCode ?generalArea . }}\n",
    "            OPTIONAL {{ ?x gndo:affiliationAsLiteral ?affiliationLiteral . }}\n",
    "        }}\n",
    "        \"\"\".format(names, pref_names_format)\n",
    "    endpoint = SPARQLWrapper(\"http://localhost:3030/persondata\")\n",
    "    endpoint.setQuery(query_string)\n",
    "    endpoint.setReturnFormat(JSON)\n",
    "\n",
    "    #print(query_string)\n",
    "    try:\n",
    "        results = endpoint.query().convert()\n",
    "    except SPARQLExceptions.EndPointInternalError:\n",
    "        pp.pprint(\"Invalid query\")\n",
    "        pp.pprint(query_string)\n",
    "        #import sys;sys.exit()\n",
    "        return {}\n",
    "    except json.decoder.JSONDecodeError as e:\n",
    "        pp.pprint(e)\n",
    "        pp.pprint(\"Couldn't decode answer!\")\n",
    "        pp.pprint(query_string)\n",
    "        return {}\n",
    "\n",
    "    results = results[\"results\"][\"bindings\"]\n",
    "    if len(results) == 0:\n",
    "        print(\"results is empty\")\n",
    "        print(names)\n",
    "        #sys.exit()\n",
    "        return {}\n",
    "    else:\n",
    "        print(\"sucessfully linked\")\n",
    "        #print(results)\n",
    "   \n",
    "    unique_candidate_dict = {}\n",
    "    for result in results:\n",
    "        uid = result[\"gid\"][\"value\"]\n",
    "        unique_candidate_dict.setdefault(uid, dict())\n",
    "        for attname, attvalue in result.items():\n",
    "            unique_candidate_dict[uid].setdefault(attname,set()).add(attvalue[\"value\"])\n",
    "    #now prepare the candidates the same way he did for metagrid:\n",
    "    \n",
    "    #print(unique_candidate_dict)\n",
    "    return unique_candidate_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "def extract_field_by_gnd(field, gnd_id, is_per = False):\n",
    "    lobid_url = \"http://lobid.org/gnd/\"+gnd_id+\".json\"\n",
    "    try:\n",
    "        res = requests.get(lobid_url, timeout=5)\n",
    "    except requests.ReadTimeout:\n",
    "        return \"\"\n",
    "    if (res.status_code != 200):\n",
    "        return \"\"\n",
    "    try:\n",
    "        lobid_json = json.loads(res.text)\n",
    "    except ValueError:\n",
    "        print(\"this url: \"+ lobid_url + \" threw a json decode error\")\n",
    "        return \"\"\n",
    "    if is_per:\n",
    "        print(lobid_json.keys())\n",
    "        field_list = []\n",
    "        for i in lobid_json[field]:\n",
    "            field_list.append(i[\"label\"])\n",
    "        return field_list\n",
    "    else:\n",
    "        #profession and place gnds\n",
    "        return lobid_json[\"preferredName\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from candidate_generation import get_coords_from_candidate\n",
    "def process_fuseki_candidates(candidates):\n",
    "    \"\"\"\n",
    "    fuseki candidates are given to us in the form:\n",
    "    candidates created via fuseki is a dictionary with key gnd_id and the values are sets.\n",
    "    example\n",
    "    116272295\n",
    "        \"x\" : {'https://d-nb.info/gn.../116272295'}\n",
    "        \"gid\" : {'116272295'}\n",
    "        \"name\" : {'b0'}\n",
    "        \"prefForename\": {'Otto'}\n",
    "        \"prefSurname\": {'Ahrens'}\n",
    "        \"y\": {'b1'}\n",
    "        \"varForename\": {'O.'}\n",
    "        \"varSurname\": {'Ahrens'}\n",
    "        \"job\": {'https://d-nb.info/gn.../4044300-0'}\n",
    "        \"activeplace\":{'https://d-nb.info/gn.../4749047-0'}\n",
    "        \"activeperiod\":{'1897'}\n",
    "        \"desc\":{'Verf. von Mecklenburgica'}\n",
    "        \"generalArea\":{'https://d-nb.info/st...code#XA-DE'}\n",
    "    and depending on the info we have even more than this (birthdate, deathdate etc)\n",
    "    \"\"\"\n",
    "    candidate_list = []\n",
    "\n",
    "    for gnd_id in candidates:\n",
    "        curr_cand = dict()\n",
    "        curr_cand[\"Gnd\"] = gnd_id\n",
    "\n",
    "        curr_cand[\"PrefName\"] = []\n",
    "        curr_cand[\"FirstName\"] = []\n",
    "        curr_cand[\"LastName\"] = []\n",
    "\n",
    "        if \"prefForename\" in candidates[gnd_id]:\n",
    "            firstnames_list = list(candidates[gnd_id][\"prefForename\"])\n",
    "            curr_cand[\"FirstName\"] += firstnames_list\n",
    "        if \"prefSurname\" in candidates[gnd_id]:\n",
    "            lastnames_list = list(candidates[gnd_id][\"prefSurname\"])\n",
    "            curr_cand[\"LastName\"] += lastnames_list\n",
    "        \n",
    "        if  \"prefForename\" in candidates[gnd_id] and \"prefSurname\" in candidates[gnd_id]:\n",
    "            curr_cand[\"PrefName\"] = [\" \".join(curr_cand[\"LastName\"]) + \", \" + \" \".join(curr_cand[\"FirstName\"])]\n",
    "        \n",
    "        if curr_cand[\"FirstName\"] == []:\n",
    "            if \"varForename\" in candidates[gnd_id]:\n",
    "                varfirstnames_list = list(candidates[gnd_id][\"varForename\"])\n",
    "                curr_cand[\"FirstName\"] += varfirstnames_list\n",
    "        if curr_cand[\"LastName\"] == []:\n",
    "            if \"varSurname\" in candidates[gnd_id]:\n",
    "                varlastnames_list = list(candidates[gnd_id][\"varSurname\"])\n",
    "                curr_cand[\"LastName\"] += varlastnames_list\n",
    "        #we do not set prefName according to the varnames even if we have no prefnames.\n",
    "        \n",
    "        #take care of duplicates\n",
    "        curr_cand[\"LastName\"] = list(set(curr_cand[\"LastName\"]))\n",
    "        curr_cand[\"FirstName\"] = list(set(curr_cand[\"FirstName\"]))\n",
    "\n",
    "        curr_cand[\"Biography\"] = []\n",
    "        if \"desc\" in candidates[gnd_id]:\n",
    "            for i in candidates[gnd_id][\"desc\"]:\n",
    "                curr_cand[\"Biography\"].append(i)\n",
    "        \n",
    "        curr_cand[\"Places\"] = []\n",
    "        if \"activeplace\" in candidates[gnd_id]:\n",
    "            for i in candidates[gnd_id][\"activeplace\"]:\n",
    "                activeplace = extract_field_by_gnd(\"placeOfActivity\", i.split(\"/\")[-1], False)\n",
    "                if activeplace != \"\":\n",
    "                    curr_cand[\"Places\"].append(activeplace)\n",
    "        if \"birthplace\" in candidates[gnd_id]:\n",
    "            for i in candidates[gnd_id][\"birthplace\"]:\n",
    "                birthplace = extract_field_by_gnd(\"placeOfBirth\", i.split(\"/\")[-1], False)\n",
    "                if birthplace != \"\":\n",
    "                    curr_cand[\"Places\"].append(birthplace)\n",
    "        if \"deathplace\" in candidates[gnd_id]:\n",
    "            for i in candidates[gnd_id][\"deathplace\"]:\n",
    "                deathplace = extract_field_by_gnd(\"placeOfDeath\", i.split(\"/\")[-1], False)\n",
    "                if deathplace != \"\":\n",
    "                    curr_cand[\"Places\"] .append(deathplace)\n",
    "        if \"generalArea\" in candidates[gnd_id]:\n",
    "            for i in candidates[gnd_id][\"generalArea\"]:\n",
    "                general_area = extract_field_by_gnd(\"geographicAreaCode\", i.split(\"/\")[-1], False)\n",
    "                if general_area != \"\":\n",
    "                    curr_cand[\"Places\"].append(general_area)\n",
    "        \n",
    "        curr_cand[\"Professions\"] = []\n",
    "        if \"job\" in candidates[gnd_id]:\n",
    "            for i in candidates[gnd_id][\"job\"]:\n",
    "                curr_job = extract_field_by_gnd(\"professionOrOccupation\", i.split(\"/\")[-1], False)\n",
    "                curr_cand[\"Professions\"].append(curr_job)\n",
    "        \n",
    "        curr_cand[\"Death Year\"] = 0\n",
    "        if \"deathdate\" in candidates[gnd_id]:\n",
    "            dates = \" \".join(candidates[gnd_id][\"deathdate\"])\n",
    "            year_regex = re.findall(r'\\d{4}', dates)\n",
    "            year_regex.sort()\n",
    "            if (len(year_regex) != 0):\n",
    "                curr_cand[\"Death Year\"] = int(year_regex[-1])\n",
    "        curr_cand[\"Birth Year\"] = 0\n",
    "        if \"birthdate\" in candidates[gnd_id]:\n",
    "            dates = \" \".join(candidates[gnd_id][\"birthdate\"])\n",
    "            year_regex = re.findall(r'\\d{4}', dates)\n",
    "            year_regex.sort()\n",
    "            if (len(year_regex) != 0):\n",
    "                curr_cand[\"Birth Year\"] = int(year_regex[0])\n",
    "                   \n",
    "        curr_cand.update(get_coords_from_candidate(curr_cand))\n",
    "\n",
    "        candidate_list.append(curr_cand)\n",
    "    #and append the empty candidate\n",
    "    empty_candidate = {'Gnd': '',\n",
    "                        'PrefName': [],\n",
    "                        'FirstName': [],\n",
    "                        'LastName': [],\n",
    "                        'Biography': [],\n",
    "                        'Places': [],\n",
    "                        'Professions': [],\n",
    "                        'Death Year': 0,\n",
    "                        'Birth Year': 0,\n",
    "                        'coordinates': []}\n",
    "    candidate_list.append(empty_candidate)\n",
    "    return candidate_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83044df59dce4e70941c4a14c8d83cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19be1b9550fc4ca49b236c6243a93783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load everytime you run this as we pop keys to keep data clean..\n",
    "with open(\"data/processed.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "for split in [\"train\", \"eval\", \"test\"]:\n",
    "    ent_cand_label = []\n",
    "    i = 0\n",
    "    for entity_list in tqdm(data[split], smoothing=0.01):\n",
    "        i += 1\n",
    "        # Create candidates only for the first entry in the list as all the entity information is always the same\n",
    "        # The only thing that changes are pages and page_coordinates\n",
    "        candidates = create_metagrid_candidates(ent=entity_list[0][\"ent\"])\n",
    "        # Generate the list of page_coordinates and the corresponding labels!\n",
    "        coord_list = []\n",
    "        label_list = []\n",
    "        for ent_dict in entity_list:\n",
    "            ent = ent_dict[\"ent\"]\n",
    "            coord_list.append({\n",
    "                \"page\": ent.pop(\"page\", \"\"), \n",
    "                \"coords\": ent.pop(\"coord\", \"\")\n",
    "            })\n",
    "            label_list.append(ent_dict[\"label\"])\n",
    "        ent_cand_label.append({\"entity\": ent, \"candidates\": candidates, \"occurences\": coord_list, \"labels\": label_list})\n",
    "        if i % 100 == 0:\n",
    "            with open(f\"candidates-gnd-{split}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(ent_cand_label, f)\n",
    "                    \n",
    "    with open(f\"candidates-gnd-{split}.pkl\", \"wb\") as f:\n",
    "       pickle.dump(ent_cand_label, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get the relevant fastttext model uncomment and run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models.fasttext import FastText, load_facebook_vectors\n",
    "# model = load_facebook_vectors(\"cc.de.300.bin/cc.de.300.bin\")\n",
    "# model.save(\"./fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.notebook import  tqdm\n",
    "from feature_generation import candidates_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d02b434b3e46c0a55a8cf2d79d728d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667ede6cebea4fe2aadb805e7dedae83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e227acf3d41741dfbf4c18d26a7fe859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AF:\n",
    "from tqdm import tqdm\n",
    "# load everytime you run this as we pop keys to keep data clean..\n",
    "with open(\"data/processed.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "problematic_entities = []\n",
    "#for split in [\"train\", \"eval\", \"test\"]:\n",
    "for split in [\"train\", \"test\"]:\n",
    "#for split in [\"eval\"]:\n",
    "    ent_cand_label = []\n",
    "    i = 0\n",
    "    for entity_list in tqdm(data[split], smoothing=0.01):\n",
    "        i += 1\n",
    "        # Create candidates only for the first entry in the list as all the entity information is always the same\n",
    "        # The only thing that changes are pages and page_coordinates\n",
    "        \n",
    "        #fuseki:\n",
    "        unique_candidate_dict = get_candidates_fuseki(entity_list[0][\"ent\"])\n",
    "        candidates = process_fuseki_candidates(unique_candidate_dict)\n",
    "        #print(process_fuseki_candidates(unique_candidate_dict))\n",
    "        #list_of_tuples.append((ent, processed_fuseki_cands, ent_dict[\"label\"]))\n",
    "        \n",
    "        #metagrid\n",
    "        ## candidates = create_metagrid_candidates(ent=entity_list[0][\"ent\"])\n",
    "        # Generate the list of page_coordinates and the corresponding labels!\n",
    "        coord_list = []\n",
    "        gt_label = []\n",
    "        for ent_dict in entity_list:\n",
    "            ent = ent_dict[\"ent\"]\n",
    "            coord_list.append({\n",
    "                \"page\": ent.pop(\"page\", \"\"), \n",
    "                \"coords\": ent.pop(\"coord\", \"\")\n",
    "            })\n",
    "            gt_label.append(ent_dict[\"label\"])\n",
    "\n",
    "        #if len(gt_label)!=1:\n",
    "        #    problematic_entities.append({\"ent_list\": entity_list, \"gt_labels\": gt_label, \"mag\": coord_list})\n",
    "            \n",
    "\n",
    "        #gt_label = gt_label.pop()\n",
    "        \n",
    "        ent_cand_label.append({\"entity\": ent, \"candidates\": candidates, \"occurences\": coord_list, \"gt_label\": gt_label})\n",
    "        if i % 100 == 0:\n",
    "            with open(f\"data/candidates/candidates-gnd-{split}-{i}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(ent_cand_label, f)\n",
    "                    \n",
    "    with open(f\"data/candidates/candidates-gnd-{split}.pkl\", \"wb\") as f:\n",
    "       pickle.dump(ent_cand_label, f)\n",
    "print(problematic_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText, load_facebook_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_facebook_vectors(\"cc.de.300.bin/cc.de.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"./fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\genta\\anaconda3\\envs\\cs4nlp\\lib\\site-packages\\thefuzz\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import  tqdm\n",
    "from feature_generation import create_features, get_gnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for split in [\"train\", \"eval\", \"test\"]:\n",
    "#for split in [\"eval\"]:\n",
    "    with open(f\"data/candidates/candidates-gnd-{split}.pkl\", \"rb\") as f:\n",
    "        ent_cand_label = pickle.load(f)\n",
    "\n",
    "    list_of_good_entities = []\n",
    "    list_of_problematic_entities = []\n",
    "    for ent_dict in tqdm(ent_cand_label):\n",
    "        if len(set(ent_dict[\"labels\"])) > 1:\n",
    "            for label in set(ent_dict[\"labels\"]):\n",
    "                ent_dict[\"label\"] = label\n",
    "                features = candidates_to_features(ent=ent_dict[\"entity\"], candidates=ent_dict[\"candidates\"], gt_label=ent_dict[\"label\"])\n",
    "                ent_dict.update(features)\n",
    "                list_of_problematic_entities.append(ent_dict.copy())\n",
    "        else:\n",
    "            ent_dict[\"label\"] = set(ent_dict[\"labels\"]).pop()\n",
    "            features = candidates_to_features(ent=ent_dict[\"entity\"], candidates=ent_dict[\"candidates\"], gt_label=ent_dict[\"label\"])\n",
    "            ent_dict.update(features)\n",
    "            list_of_good_entities.append(ent_dict)\n",
    "            \n",
    "    with open(f\"data/features/{split}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(list_of_good_entities, file=f)\n",
    "    \n",
    "    with open(f\"data/features/{split}_problematic.pkl\", \"wb\") as f:\n",
    "        pickle.dump(list_of_problematic_entities, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\genta\\git\\ETH-CS4NLP-22-Project-Linking-GND\\linking.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/genta/git/ETH-CS4NLP-22-Project-Linking-GND/linking.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/genta/git/ETH-CS4NLP-22-Project-Linking-GND/linking.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/genta/git/ETH-CS4NLP-22-Project-Linking-GND/linking.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfeature_generation\u001b[39;00m \u001b[39mimport\u001b[39;00m get_gnd\n",
      "File \u001b[1;32mc:\\Users\\genta\\git\\ETH-CS4NLP-22-Project-Linking-GND\\feature_generation.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_gnd\n\u001b[0;32m     10\u001b[0m loc \u001b[39m=\u001b[39m Nominatim(user_agent\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGetLoc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m ft \u001b[39m=\u001b[39m FastTextKeyedVectors\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m./fasttext\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_min_distance\u001b[39m(pairs):\n\u001b[0;32m     14\u001b[0m     distances \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\genta\\anaconda3\\envs\\cs4nlp\\lib\\site-packages\\gensim\\models\\fasttext.py:1001\u001b[0m, in \u001b[0;36mFastTextKeyedVectors.load\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    982\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mcls\u001b[39m, fname_or_handle, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    983\u001b[0m     \u001b[39m\"\"\"Load a previously saved `FastTextKeyedVectors` model.\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \n\u001b[0;32m    985\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    999\u001b[0m \n\u001b[0;32m   1000\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1001\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(FastTextKeyedVectors, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39mload(fname_or_handle, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\genta\\anaconda3\\envs\\cs4nlp\\lib\\site-packages\\gensim\\utils.py:486\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    482\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m object from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, fname)\n\u001b[0;32m    484\u001b[0m compress, subname \u001b[39m=\u001b[39m SaveLoad\u001b[39m.\u001b[39m_adapt_by_suffix(fname)\n\u001b[1;32m--> 486\u001b[0m obj \u001b[39m=\u001b[39m unpickle(fname)\n\u001b[0;32m    487\u001b[0m obj\u001b[39m.\u001b[39m_load_specials(fname, mmap, compress, subname)\n\u001b[0;32m    488\u001b[0m obj\u001b[39m.\u001b[39madd_lifecycle_event(\u001b[39m\"\u001b[39m\u001b[39mloaded\u001b[39m\u001b[39m\"\u001b[39m, fname\u001b[39m=\u001b[39mfname)\n",
      "File \u001b[1;32mc:\\Users\\genta\\anaconda3\\envs\\cs4nlp\\lib\\site-packages\\gensim\\utils.py:1460\u001b[0m, in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munpickle\u001b[39m(fname):\n\u001b[0;32m   1447\u001b[0m     \u001b[39m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \n\u001b[0;32m   1449\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \n\u001b[0;32m   1459\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1460\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(fname, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m   1461\u001b[0m         \u001b[39mreturn\u001b[39;00m _pickle\u001b[39m.\u001b[39mload(f, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\genta\\anaconda3\\envs\\cs4nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:177\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m transport_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     transport_params \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 177\u001b[0m fobj \u001b[39m=\u001b[39m _shortcut_open(\n\u001b[0;32m    178\u001b[0m     uri,\n\u001b[0;32m    179\u001b[0m     mode,\n\u001b[0;32m    180\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    181\u001b[0m     buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[0;32m    182\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    183\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    184\u001b[0m     newline\u001b[39m=\u001b[39;49mnewline,\n\u001b[0;32m    185\u001b[0m )\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32mc:\\Users\\genta\\anaconda3\\envs\\cs4nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:363\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m    361\u001b[0m     open_kwargs[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m errors\n\u001b[1;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[39m=\u001b[39mbuffering, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './fasttext'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from feature_generation import get_gnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"train\": {}, \"eval\": {}}\n",
    "for split in [\"train\", \"eval\"]:\n",
    "    with open(f\"data/features/{split}.pkl\", \"rb\") as f:\n",
    "        d[split] = pickle.load(file=f)\n",
    "\n",
    "d_problem = {\"train\": {}, \"eval\": {}}\n",
    "for split in [\"train\", \"eval\"]:\n",
    "    with open(f\"data/features/{split}_problematic.pkl\", \"rb\") as f:\n",
    "        d_problem[split] = pickle.load(file=f)\n",
    "\n",
    "d_combined = {\"train\": d[\"train\"]+d_problem[\"train\"], \"eval\": d[\"eval\"] + d_problem[\"eval\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best scores I could get so far**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity Level\n",
      "N: 1 Treshold: 0.01\n",
      "F1: 0.69 RE:  0.526 PR: 1.0 AC: 0.633\n",
      "TP: 20 TN: 18 FP 0 TN 11\n",
      "\n",
      "\n",
      "N: 10 Treshold: 0.01\n",
      "F1: 0.69 RE:  0.526 PR: 1.0 AC: 0.633\n",
      "TP: 20 TN: 18 FP 0 TN 11\n",
      "\n",
      "\n",
      "Mention Level\n",
      "N: 1 Treshold: 0.01\n",
      "F1: 0.77 RE:  0.626 PR: 1.0 AC: 0.706\n",
      "TP: 62 TN: 37 FP 0 TN 27\n",
      "\n",
      "\n",
      "N: 10 Treshold: 0.01\n",
      "F1: 0.77 RE:  0.626 PR: 1.0 AC: 0.706\n",
      "TP: 62 TN: 37 FP 0 TN 27\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ent_scores, ment_scores = perform_experiment(\n",
    "    keep_empty=True, \n",
    "    do_sample=True,\n",
    "    oversampling=1, # Multiple of how often we oversample y = 1\n",
    "    balance=1, # multiple of y = 0 samples vs y = 1 samples\n",
    "    d=d_combined, \n",
    "    model=ExtraTreesRegressor(n_estimators=100, random_state=0, criterion=\"squared_error\", bootstrap=True),\n",
    "    n_s=[1,10], # How many candidates do we keep\n",
    "    tresholds=[0.01], # Where do we cut off\n",
    "    verbose=False # Print stuff\n",
    ")\n",
    "print(\"\\nEntity Level\")\n",
    "for score in ent_scores:\n",
    "    print(\"N:\", score[\"top_n\"], \"Treshold:\", score[\"treshold\"])\n",
    "    score[\"score\"].print_scores()\n",
    "\n",
    "print(\"Mention Level\")\n",
    "for score in ment_scores:\n",
    "    print(\"N:\", score[\"top_n\"], \"Treshold:\", score[\"treshold\"])\n",
    "    score[\"score\"].print_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "models = [\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='squared_error'),\n",
    "    ExtraTreesRegressor(n_estimators=100, random_state=0, criterion=\"squared_error\", bootstrap=True),\n",
    "    ExtraTreesRegressor(n_estimators=100, random_state=0, criterion=\"absolute_error\", bootstrap=True),\n",
    "    ExtraTreesClassifier(n_estimators=100, random_state=0, bootstrap=True),\n",
    "    ElasticNet(random_state=0)\n",
    "]\n",
    "\n",
    "model_names = [\"GBR\", \"Tree Reg Squared\", \"Tree Reg Abs\", \"Tree Class\", \"Elastic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_list = [1, 2, 3, 5]\n",
    "oversampling_list = [1, 2, 3, 5]\n",
    "n_s = [1]\n",
    "tresholds = [0.01, 0.1, 0.2, 0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Tree Reg Squared\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Tree Reg Abs\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Tree Class\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Elastic\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 1\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 2\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 3\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n",
      "Balance: 5\n",
      "Oversampling: 1\n",
      "Oversampling: 2\n",
      "Oversampling: 3\n",
      "Oversampling: 5\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    print(model_name)\n",
    "    for data, data_name in zip([d, d_combined], [\"cleaned\", \"combined\"]):\n",
    "        for keep_empty in [True, False]:\n",
    "            for do_sample in [True, False]:\n",
    "                if do_sample:\n",
    "                    for balance in balance_list:\n",
    "                        #print(\"Balance:\", balance)\n",
    "                        for oversampling in oversampling_list:\n",
    "                            #print(\"Oversampling:\", oversampling)\n",
    "                            ent_scores, ment_scores = perform_experiment(keep_empty=keep_empty, \n",
    "                                do_sample=do_sample, \n",
    "                                oversampling=oversampling, \n",
    "                                balance=balance, \n",
    "                                d=data, \n",
    "                                model=model,\n",
    "                                n_s=n_s,\n",
    "                                tresholds=tresholds\n",
    "                            )\n",
    "                            results.append({\n",
    "                                \"keep_empty\": keep_empty,\n",
    "                                \"do_sample\": do_sample,\n",
    "                                \"balance\": balance,\n",
    "                                \"oversampling\": oversampling,\n",
    "                                \"ent_scores\": ent_scores,\n",
    "                                \"ment_scores\": ment_scores,\n",
    "                                \"model\": model_name,\n",
    "                                \"data\": data_name\n",
    "                            })\n",
    "                else:\n",
    "                    balance = 1\n",
    "                    oversampling = 1 \n",
    "                    ent_scores, ment_scores = perform_experiment(keep_empty=keep_empty, \n",
    "                                do_sample=do_sample, \n",
    "                                oversampling=oversampling, \n",
    "                                balance=balance, \n",
    "                                d=data, \n",
    "                                model=model,\n",
    "                                n_s=n_s,\n",
    "                                tresholds=tresholds\n",
    "                            )\n",
    "                    results.append({\n",
    "                        \"keep_empty\": keep_empty,\n",
    "                        \"do_sample\": do_sample,\n",
    "                        \"balance\": balance,\n",
    "                        \"oversampling\": oversampling,\n",
    "                        \"ent_scores\": ent_scores,\n",
    "                        \"ment_scores\": ment_scores,\n",
    "                        \"model\": model_name,\n",
    "                        \"data\": data_name\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_sample = True\n",
    "keep_empty = True\n",
    "model = \"Tree Reg Squared\"\n",
    "data = \"combined\"\n",
    "\n",
    "for balance in balance_list:\n",
    "    for oversampling in oversampling_list:\n",
    "        plot_metrics_over_treshold(\n",
    "            tresholds=tresholds, \n",
    "            n_s=n_s, \n",
    "            oversampling=oversampling, \n",
    "            balance=balance, \n",
    "            do_sample=True, \n",
    "            keep_empty=True, \n",
    "            model=model,\n",
    "            data=data,\n",
    "            results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(scores, score_name, dict, current_setup):\n",
    "    for score in scores:\n",
    "        score_dict = score[\"score\"].get_score()\n",
    "        curr_setup[\"top_n\"] = score[\"top_n\"]\n",
    "        curr_setup[\"treshold\"] = score[\"treshold\"]\n",
    "        if score_dict[score_name] > dict[f\"top_{score_name}\"]:\n",
    "            dict[f\"top_{score_name}\"] = score_dict[score_name]\n",
    "            dict[f\"top_{score_name}_setup\"] = [current_setup]\n",
    "        elif score_dict[score_name] == dict[f\"top_{score_name}\"]:\n",
    "            dict[f\"top_{score_name}_setup\"].append(current_setup)\n",
    "    return dict\n",
    "\n",
    "model_results = []\n",
    "for model_name in model_names:\n",
    "    dictionary={\n",
    "        \"ent\": {\n",
    "            \"top_F1\": 0,\n",
    "            \"top_Recall\": 0,\n",
    "            \"top_Precision\": 0,\n",
    "            \"top_F1_setup\": [],\n",
    "            \"top_Recall_setup\": [],\n",
    "            \"top_Precision_setup\": []\n",
    "        },\n",
    "        \"ment\": {\n",
    "            \"top_F1\": 0,\n",
    "            \"top_Recall\": 0,\n",
    "            \"top_Precision\": 0,\n",
    "            \"top_F1_setup\": [],\n",
    "            \"top_Recall_setup\": [],\n",
    "            \"top_Precision_setup\": []\n",
    "        }\n",
    "    }\n",
    "    for di in results:\n",
    "        if di[\"model\"] == model_name:\n",
    "            for scoring_level in [\"ent\", \"ment\"]:\n",
    "                scores = di[f\"{scoring_level}_scores\"]\n",
    "                curr_setup = {\n",
    "                    \"data\": di[\"data\"],\n",
    "                    \"do_sample\": di[\"do_sample\"],\n",
    "                    \"balance\": di[\"balance\"],\n",
    "                    \"oversampling\": di[\"oversampling\"],\n",
    "                    \"keep_empty\": di[\"keep_empty\"]\n",
    "                }\n",
    "                for score_name in [\"F1\", \"Recall\", \"Precision\"]:\n",
    "                    dictionary[scoring_level] = extract(scores, score_name, dictionary[scoring_level], curr_setup )\n",
    "    model_results.append(dictionary)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = \"F1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR\n",
      "ent\t F1:\t 0.69\n",
      "ent\t F1 Setup:\n",
      "Number of setups: 40\n",
      "Mean\n",
      "sample 1.0\n",
      "empty  1.0\n",
      "combin 0.375\n",
      "tresh  0.5\n",
      "overs  2.825\n",
      "balanc 1.825\n",
      "Median\n",
      "sample 1.0\n",
      "empty  1.0\n",
      "combin 0.0\n",
      "tresh  0.5\n",
      "overs  2.5\n",
      "balanc 2.0\n",
      "\n",
      "\n",
      "\n",
      "ment\t F1:\t 0.77\n",
      "ment\t F1 Setup:\n",
      "Number of setups: 80\n",
      "Mean\n",
      "sample 1.0\n",
      "empty  1.0\n",
      "combin 0.375\n",
      "tresh  0.5\n",
      "overs  2.825\n",
      "balanc 1.825\n",
      "Median\n",
      "sample 1.0\n",
      "empty  1.0\n",
      "combin 0.0\n",
      "tresh  0.5\n",
      "overs  2.5\n",
      "balanc 2.0\n",
      "\n",
      "\n",
      "\n",
      "Tree Reg Squared\n",
      "ent\t F1:\t 0.69\n",
      "ent\t F1 Setup:\n",
      "Number of setups: 43\n",
      "Mean\n",
      "sample 0.9534883720930233\n",
      "empty  0.8372093023255814\n",
      "combin 0.6511627906976745\n",
      "tresh  0.5\n",
      "overs  2.744186046511628\n",
      "balanc 2.3488372093023258\n",
      "Median\n",
      "sample 1.0\n",
      "empty  1.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  3.0\n",
      "balanc 2.0\n",
      "\n",
      "\n",
      "\n",
      "ment\t F1:\t 0.77\n",
      "ment\t F1 Setup:\n",
      "Number of setups: 86\n",
      "Mean\n",
      "sample 0.9534883720930233\n",
      "empty  0.8372093023255814\n",
      "combin 0.6511627906976745\n",
      "tresh  0.5\n",
      "overs  2.744186046511628\n",
      "balanc 2.3488372093023258\n",
      "Median\n",
      "sample 1.0\n",
      "empty  1.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  3.0\n",
      "balanc 2.0\n",
      "\n",
      "\n",
      "\n",
      "Tree Reg Abs\n",
      "ent\t F1:\t 0.69\n",
      "ent\t F1 Setup:\n",
      "Number of setups: 19\n",
      "Mean\n",
      "sample 0.7894736842105263\n",
      "empty  0.47368421052631576\n",
      "combin 0.47368421052631576\n",
      "tresh  0.5\n",
      "overs  2.789473684210526\n",
      "balanc 2.8947368421052633\n",
      "Median\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 0.0\n",
      "tresh  0.5\n",
      "overs  2.0\n",
      "balanc 3.0\n",
      "\n",
      "\n",
      "\n",
      "ment\t F1:\t 0.77\n",
      "ment\t F1 Setup:\n",
      "Number of setups: 38\n",
      "Mean\n",
      "sample 0.7894736842105263\n",
      "empty  0.47368421052631576\n",
      "combin 0.47368421052631576\n",
      "tresh  0.5\n",
      "overs  2.789473684210526\n",
      "balanc 2.8947368421052633\n",
      "Median\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 0.0\n",
      "tresh  0.5\n",
      "overs  2.0\n",
      "balanc 3.0\n",
      "\n",
      "\n",
      "\n",
      "Tree Class\n",
      "ent\t F1:\t 0.69\n",
      "ent\t F1 Setup:\n",
      "Number of setups: 4\n",
      "Mean\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  5.0\n",
      "balanc 3.0\n",
      "Median\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  5.0\n",
      "balanc 3.0\n",
      "\n",
      "\n",
      "\n",
      "ment\t F1:\t 0.77\n",
      "ment\t F1 Setup:\n",
      "Number of setups: 8\n",
      "Mean\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  5.0\n",
      "balanc 3.0\n",
      "Median\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  5.0\n",
      "balanc 3.0\n",
      "\n",
      "\n",
      "\n",
      "Elastic\n",
      "ent\t F1:\t 0.632\n",
      "ent\t F1 Setup:\n",
      "Number of setups: 1\n",
      "Mean\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  1.0\n",
      "balanc 5.0\n",
      "Median\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  1.0\n",
      "balanc 5.0\n",
      "\n",
      "\n",
      "\n",
      "ment\t F1:\t 0.705\n",
      "ment\t F1 Setup:\n",
      "Number of setups: 2\n",
      "Mean\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  1.0\n",
      "balanc 5.0\n",
      "Median\n",
      "sample 1.0\n",
      "empty  0.0\n",
      "combin 1.0\n",
      "tresh  0.5\n",
      "overs  1.0\n",
      "balanc 5.0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for scores, model_name in zip(model_results, model_names):\n",
    "    balance = []\n",
    "    combined = []\n",
    "    oversampling = []\n",
    "    keep_empty = []\n",
    "    do_sample = []\n",
    "    top_n = []\n",
    "    tresholds = []\n",
    "    print(model_name)\n",
    "    for scoring_level in [\"ent\", \"ment\"]:\n",
    "        print(f\"{scoring_level}\\t\", f\"{score}:\\t\", scores[scoring_level][f\"top_{score}\"])\n",
    "        print(f\"{scoring_level}\\t\", f\"{score} Setup:\")\n",
    "        for setup in scores[scoring_level][f\"top_{score}_setup\"]:\n",
    "            if setup[\"data\"] == \"cleaned\":\n",
    "                combined.append(0)\n",
    "            else:\n",
    "                combined.append(1)\n",
    "            balance.append(setup[\"balance\"])\n",
    "            oversampling.append(setup[\"oversampling\"])\n",
    "            top_n.append(setup[\"top_n\"])\n",
    "            tresholds.append(setup[\"treshold\"])\n",
    "            if setup[\"do_sample\"]:\n",
    "                do_sample.append(1)\n",
    "            else:\n",
    "                do_sample.append(0)\n",
    "            if setup[\"keep_empty\"]:\n",
    "                keep_empty.append(1)\n",
    "            else:\n",
    "                keep_empty.append(0)\n",
    "    \n",
    "        print(f\"Number of setups: {len(do_sample)}\")\n",
    "\n",
    "        print(\"Mean\")\n",
    "        print(\"sample\", np.mean(do_sample))\n",
    "        print(\"empty \", np.mean(keep_empty))\n",
    "        print(\"combin\", np.mean(combined))\n",
    "        print(\"tresh \", np.mean(tresholds))\n",
    "        #print(\"top_n \", np.mean(top_n))\n",
    "        print(\"overs \", np.mean(oversampling))\n",
    "        print(\"balanc\", np.mean(balance))\n",
    "\n",
    "        print(\"Median\")\n",
    "        print(\"sample\", np.median(do_sample))\n",
    "        print(\"empty \", np.median(keep_empty))\n",
    "        print(\"combin\", np.median(combined))\n",
    "        print(\"tresh \", np.median(tresholds))\n",
    "        #print(\"top_n \", np.median(top_n))\n",
    "        print(\"overs \", np.median(oversampling))\n",
    "        print(\"balanc\", np.median(balance))\n",
    "        print(\"\\n\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some tests we find:\n",
    "- ExtraTreesRegressor works best\n",
    "- with: \n",
    "    - Balance = 1\n",
    "    - Oversampling = 1\n",
    "    - do_sample = True\n",
    "    - keep_empty = True\n",
    "    - treshold = 0.1 or smaller is more stable in advers conditions for balance 1 and oversampling 1 it does not matter -> this makes the regression more stable\n",
    "    - => n -> does not matter so much can amolst go to 1 !!!!\n",
    "\n",
    "- problematic entities seem to help "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cs4nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c94d51cd8360e2f18432dae5114b333636d08a4ea226f055bf446eeb779cd30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
